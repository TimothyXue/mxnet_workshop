{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Segmentation with Pre-trained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can often leverage pre-trained models contributed by the community. The [MXNet Model Zoo](http://mxnet.io/model_zoo/) contains fast implementations of many state-of-the-art models, with pre-trained weights included.\n",
    "\n",
    "In this tutorial, we demonstrate how to use a pre-trained network and perform prediction on a new image.\n",
    "\n",
    "The task here is image segmentation, where the network learns to assign each pixel to a category, such as shown below:\n",
    "\n",
    "<img src=\"images/seg_image.png\">\n",
    "\n",
    "Here we use a pre-trained segmentation model called FCN-xs (based on [this](https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf) publication). This is a convolutional neural network that was trained on the PASCAL VOC 2011 dataset, which includes 2,207 images similar to those above. \n",
    "\n",
    "Each image was annotated to segment twenty classes of objects: `person, bird, cat, cow, dog, horse, sheep, aeroplane, bicycle, boat, bus, car, motorbike, train, bottle, chair, dining table, potted plant, and tv monitor`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The required model files are hosted at https://bitbucket.org/krishnasumanthm/mxnet_image_segmentation\n",
    "\n",
    "We first define a download function and download pre-trained model, symbol file and a test image.\n",
    "\n",
    "Note: The pre-trained model is about 500MB, so first time downloading might take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os, urllib2, time\n",
    "import warnings\n",
    "warnings.simplefilter('ignore',DeprecationWarning)\n",
    "import sys\n",
    "from PIL import Image\n",
    "import utils "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model\n",
    "\n",
    "We first load the model by calling the `mx.model.load_checkpoint()` method. This loads the network definiton, which based on a `json` file, and the pre-trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params, states = mx.model.load_checkpoint('data/FCN8s_VGG16', epoch=19) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model's weights are stored in the `params` dictionary, and easy to inspect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, here we compute the average magnitude of the weights in the first convolutional layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['conv1_1_weight']  # this is an array of size (64, 3, 3, 3)\n",
    "\n",
    "magnitude = np.mean(np.abs(params['conv1_1_weight'].asnumpy()))\n",
    "print \"First layer weights have average magnitude of: {}\".format(magnitude)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the data for evaluation\n",
    "Below we create a helper function to load the image, perform some minor preprocessing, and then convert the image to a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_path):\n",
    "    # Function to convert input image to np.array\n",
    "    \"\"\"get the (1, 3, h, w) np.array data for the img_path\"\"\"\n",
    "    mean = np.array([123.68, 116.779, 103.939])  # (R,G,B)\n",
    "    \n",
    "    img = Image.open(img_path)\n",
    "    img.thumbnail((800, 800), Image.ANTIALIAS)\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    reshaped_mean = mean.reshape(1, 1, 3)\n",
    "    img = img - reshaped_mean\n",
    "    img = np.swapaxes(img, 0, 2)\n",
    "    img = np.swapaxes(img, 1, 2)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model\n",
    "\n",
    "Then, we create a function below that:\n",
    "1. Tells the model what the input image size to expect.\n",
    "2. Creates an executor, while binding the loaded parameters and states\n",
    "3. Runs the inference pass via `forward()` method.\n",
    "4. Saves the images and display in notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img_path, model, params, states):\n",
    "    img = load_image(img_path)\n",
    "    \n",
    "    # Input images are stored in a 4-D matrix \n",
    "    params[\"data\"] = mx.nd.array(img, mx.cpu()) \n",
    "    data_shape = params[\"data\"].shape\n",
    "    \n",
    "    # Output image has the same number of pixels\n",
    "    label_shape = (1, data_shape[2]*data_shape[3])\n",
    "    params[\"softmax_label\"] = mx.nd.empty(label_shape, mx.cpu())\n",
    "    \n",
    "    # create an 'executor' and bind the parameters and states\n",
    "    executor = model.bind(mx.cpu(), params, aux_states=states)\n",
    "\n",
    "    tic = time.time()\n",
    "\n",
    "    # run the inference pass\n",
    "    executor.forward(is_train=False)\n",
    "    print \"Time taken for forward pass: {:.3f} milli sec\".format((time.time()-tic)*1000)\n",
    "\n",
    "    # save the images and print the results\n",
    "    print \"Saving images...\"\n",
    "    utils.print_images(executor.outputs[0], img_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"person_bicycle.jpg\", model, params, states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
